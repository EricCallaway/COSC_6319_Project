{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "biLSTM_reviews_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1RVkFbKXJkzVxw6fqxep2OxifS8WlCFau",
      "authorship_tag": "ABX9TyPQ/mvarxO4acJlcVxu3t1I",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EricCallaway/COSC_6319_Project/blob/NavyaMakkena_COSC_6319_Project/biLSTM_reviews_summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7isZ4DmgTmr",
        "outputId": "06365a63-9d17-4223-c32c-7fef57688c1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 88421 entries, 0 to 99999\n",
            "Data columns (total 10 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   Id                      88421 non-null  int64 \n",
            " 1   ProductId               88421 non-null  object\n",
            " 2   UserId                  88421 non-null  object\n",
            " 3   ProfileName             88421 non-null  object\n",
            " 4   HelpfulnessNumerator    88421 non-null  int64 \n",
            " 5   HelpfulnessDenominator  88421 non-null  int64 \n",
            " 6   Score                   88421 non-null  int64 \n",
            " 7   Time                    88421 non-null  int64 \n",
            " 8   Summary                 88421 non-null  object\n",
            " 9   Text                    88421 non-null  object\n",
            "dtypes: int64(5), object(5)\n",
            "memory usage: 7.4+ MB\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data=pd.read_csv(\"/content/drive/My Drive/Colab Notebooks/Reviews.csv\",nrows=100000)\n",
        "data.drop_duplicates(subset=['Text'],inplace=True)#dropping duplicates\n",
        "data.dropna(axis=0,inplace=True)#dropping na\n",
        "\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oJThOCrgmcD",
        "outputId": "1b923234-0068-4e83-9ca5-a508e90db84d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting contractions\n",
            "  Downloading contractions-0.1.72-py2.py3-none-any.whl (8.3 kB)\n",
            "Collecting textsearch>=0.0.21\n",
            "  Downloading textsearch-0.0.21-py2.py3-none-any.whl (7.5 kB)\n",
            "Collecting anyascii\n",
            "  Downloading anyascii-0.3.1-py3-none-any.whl (287 kB)\n",
            "\u001b[K     |████████████████████████████████| 287 kB 3.8 MB/s \n",
            "\u001b[?25hCollecting pyahocorasick\n",
            "  Downloading pyahocorasick-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 48.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: pyahocorasick, anyascii, textsearch, contractions\n",
            "Successfully installed anyascii-0.3.1 contractions-0.1.72 pyahocorasick-1.4.4 textsearch-0.0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from bs4 import BeautifulSoup\n",
        "import contractions\n",
        "import numpy as np\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def text_lowercase(text):\n",
        "    return text.lower()\n",
        "\n",
        "def remove_numbers(text):\n",
        "    output_text = re.sub(r'\\d+', '', text)\n",
        "    return output_text\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    return text.translate(translator)\n",
        "\n",
        "def remove_whitespace(text):\n",
        "    return  text.strip()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    stop_words = set(stopwords.words(\"english\"))\n",
        "    filtered_text = \" \".join([word for word in str(text).split() if word not in stop_words])\n",
        "    return filtered_text\n",
        "\n",
        "def remove_html(dataText):\n",
        "    return BeautifulSoup(dataText, \"lxml\").text\n",
        "\n",
        "def contraction_mapping(text):\n",
        "    expanded_words = []   \n",
        "    for word in text.split():\n",
        "    # using contractions.fix to expand the shortened words\n",
        "      expanded_words.append(contractions.fix(word))  \n",
        "    expanded_text = ' '.join(expanded_words)\n",
        "    return expanded_text\n",
        "\n",
        "def lemmatization(text):\n",
        "   lemmatizer = WordNetLemmatizer()\n",
        "   return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
        "\n",
        "\n",
        "\n",
        "def cleaning_data(content):\n",
        "    # Lowercase text\n",
        "    content = text_lowercase(content)\n",
        "\n",
        "    # Remove numbers\n",
        "    content = remove_numbers(content)\n",
        "\n",
        "    # remove punctuation\n",
        "    content = remove_punctuation(content)\n",
        "\n",
        "    # remove whitespace from text\n",
        "    content = remove_whitespace(content)\n",
        "\n",
        "    # remove html from string\n",
        "    content = remove_html(content)\n",
        "\n",
        "    # contraction mapping\n",
        "    content = contraction_mapping(content)\n",
        "\n",
        "    # remove stopwords\n",
        "    content = remove_stopwords(content)\n",
        "\n",
        "    # lemmatization\n",
        "    content = lemmatization(content)\n",
        "    return content\n",
        "\n",
        "print(data['Text'][0])\n",
        "cleaned_text = []\n",
        "for t in data['Text']:\n",
        "    cleaned_text.append(cleaning_data(t))\n",
        "\n",
        "print(cleaned_text[:5])\n",
        "\n",
        "cleaned_summary = []\n",
        "for t in data['Summary']:\n",
        "    cleaned_summary.append(cleaning_data(t))\n",
        "\n",
        "print(cleaned_summary[:10])\n",
        "\n",
        "data.replace('', np.nan, inplace=True)\n",
        "data.dropna(axis=0,inplace=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnhsegpTguJI",
        "outputId": "acb69686-6836-49cd-896e-fce25e57968e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n",
            "['bought several vitality canned dog food product found good quality product look like stew processed meat smell better labrador finicky appreciates product better', 'product arrived labeled jumbo salted peanutsthe peanut actually small sized unsalted sure error vendor intended represent product jumbo', 'confection around century light pillowy citrus gelatin nut case filbert cut tiny square liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sister witch', 'looking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal', 'great taffy great price wide assortment yummy taffy delivery quick taffy lover deal']\n",
            "['good quality dog food', 'advertised', 'delight say', 'cough medicine', 'great taffy', 'nice taffy', 'great good expensive brand', 'wonderful tasty taffy', 'yay barley', 'healthy dog food']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_text_len=30\n",
        "max_summary_len=8"
      ],
      "metadata": {
        "id": "RmSxztRKhf7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_text =np.array(cleaned_text)\n",
        "cleaned_summary=np.array(cleaned_summary)\n",
        "\n",
        "short_text=[]\n",
        "short_summary=[]\n",
        "\n",
        "for i in range(len(cleaned_text)):\n",
        "    if(len(cleaned_summary[i].split())<=max_summary_len and len(cleaned_text[i].split())<=max_text_len):\n",
        "        short_text.append(cleaned_text[i])\n",
        "        short_summary.append(cleaned_summary[i])\n",
        "        \n",
        "df=pd.DataFrame({'text':short_text,'summary':short_summary})\n",
        "\n",
        "df['summary'] = df['summary'].apply(lambda x : 'sostok '+ x + ' eostok')\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(np.array(df['text']),np.array(df['summary']),test_size=0.1,random_state=0,shuffle=True) "
      ],
      "metadata": {
        "id": "6t6uKsEmhjMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "VOCAB_SIZE = 50000\n",
        "article_tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "# articles\n",
        "article_tokenizer.fit_on_texts(list(x_tr))\n",
        "article_sequences = article_tokenizer.texts_to_sequences(x_tr)\n",
        "article_val_seq   =   article_tokenizer.texts_to_sequences(x_val)\n",
        "art_word_index = article_tokenizer.word_index\n",
        "print(len(art_word_index))\n",
        "# summaries\n",
        "summary_tokenizer = Tokenizer(num_words=VOCAB_SIZE)\n",
        "summary_tokenizer.fit_on_texts(list(y_tr))\n",
        "summary_sequences = summary_tokenizer.texts_to_sequences(y_tr)\n",
        "summary_val_seq   = summary_tokenizer.texts_to_sequences(y_val) \n",
        "summary_word_index = summary_tokenizer.word_index\n",
        "print(len(summary_word_index))\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "x_tr = pad_sequences(article_sequences, maxlen=max_text_len, padding='post', truncating='post')\n",
        "y_tr = pad_sequences(summary_sequences, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "x_val = pad_sequences(article_val_seq, maxlen=max_text_len, padding='post', truncating='post')\n",
        "y_val = pad_sequences(summary_val_seq, maxlen=max_summary_len, padding='post', truncating='post')\n",
        "\n",
        "print(x_tr.shape)\n",
        "print(y_tr.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4oM9h3gjKo9",
        "outputId": "0cd17d29-9bb0-4702-a0a2-2198ca634ae4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "30811\n",
            "9142\n",
            "(42820, 30)\n",
            "(42820, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "embeddings_index = {}\n",
        "with open('/content/drive/My Drive/Colab Notebooks/glove.6B.200d.txt', encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_dim = 200\n",
        "hits = 0\n",
        "misses = 0\n",
        "\n",
        "# Prepare embedding matrix for articles\n",
        "article_embedding_matrix = np.zeros(((len(art_word_index)+1), embedding_dim))\n",
        "for word, i in art_word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        article_embedding_matrix[i] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "print(article_embedding_matrix.shape)\n",
        "\n",
        "# Prepare embedding matrix for summaries\n",
        "hits=0\n",
        "misses = 0\n",
        "summary_embedding_matrix = np.zeros((len(summary_word_index) + 1, embedding_dim))\n",
        "for word, j in summary_word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # Words not found in embedding index will be all-zeros.\n",
        "        # This includes the representation for \"padding\" and \"OOV\"\n",
        "        summary_embedding_matrix[j] = embedding_vector\n",
        "        hits += 1\n",
        "    else:\n",
        "        misses += 1\n",
        "print(\"Converted %d words (%d misses)\" % (hits, misses))\n",
        "print(summary_embedding_matrix.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_tP9cYokiCp",
        "outputId": "5eb3f8b9-4710-47a9-d866-5de49c0a300b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 400001 word vectors.\n",
            "Converted 16459 words (14352 misses)\n",
            "(30812, 200)\n",
            "Converted 6681 words (2461 misses)\n",
            "(9143, 200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding\n",
        "import keras.initializers\n",
        "\n",
        "encoder_embedding_layer = Embedding(\n",
        "    input_dim = article_embedding_matrix.shape[0], #num_distinct_words\n",
        "    output_dim = embedding_dim, #embedding_output_dims\n",
        "    input_length = max_text_len, #max_sequence_length\n",
        "    embeddings_initializer= keras.initializers.Constant(article_embedding_matrix),\n",
        "    trainable = True\n",
        ")\n",
        "\n",
        "decoder_embedding_layer = Embedding(\n",
        "    input_dim = summary_embedding_matrix.shape[0],\n",
        "    output_dim = embedding_dim,\n",
        "    input_length = max_summary_len,\n",
        "    embeddings_initializer= keras.initializers.Constant(summary_embedding_matrix),\n",
        "    trainable = True\n",
        ")"
      ],
      "metadata": {
        "id": "iBV4qDvDksHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras\n",
        "from keras import layers\n",
        "from keras.layers import Dense,LSTM,Dropout,Input,Activation,Bidirectional,TimeDistributed\n",
        "\n",
        "# Input layer\n",
        "encoder_input = layers.Input(shape=(max_text_len))\n",
        "encoder_embedded = encoder_embedding_layer(encoder_input)\n",
        "\n",
        "# Decoder -- LSTM\n",
        "decoder_input = layers.Input(shape=(None,))\n",
        "decoder_embedded = decoder_embedding_layer(decoder_input)\n",
        "\n",
        "# Encoder 1 -- Bidirectional LSTM 1\n",
        "encoder1_output, forward_h1, forward_c1 ,backward_h1, backward_c1= Bidirectional(layers.LSTM(200, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4,name=\"encoder1\"),merge_mode=\"concat\")(\n",
        "    encoder_embedded\n",
        ")\n",
        "# Encoder 2 -- Bidirectional LSTM 2\n",
        "encode2_output, forward_h2, forward_c2 ,backward_h2, backward_c2= Bidirectional(layers.LSTM(200, return_state=True, return_sequences=True,dropout=0.4,recurrent_dropout=0.4,name=\"encoder2\"),merge_mode=\"concat\")(\n",
        "    encoder1_output,initial_state=[forward_h1,backward_h1,forward_c1,backward_c1]\n",
        ")\n",
        "state_h2 =  layers.Concatenate()([forward_h2, backward_h2])\n",
        "state_c2 =  layers.Concatenate()([forward_c2, backward_c2])\n",
        "encoder2_state = [state_h2,state_c2]\n",
        "\n",
        "# Pass the encoder 2 state to decoder LSTM layer, as initial state\n",
        "decoder_LSTM= layers.LSTM(400,return_sequences=True, return_state=True,dropout=0.4,recurrent_dropout=0.2,name=\"decoder\")\n",
        "decoder_output,decoder_state_h1 ,decoder_state_c1 = decoder_LSTM(\n",
        "    decoder_embedded, initial_state=encoder2_state\n",
        ")\n",
        "# Dense layer with activation\n",
        "decoder_dense = TimeDistributed(layers.Dense(len(summary_word_index)+1,activation='softmax'))\n",
        "decoder_output = decoder_dense(decoder_output)\n",
        "\n",
        "model = keras.Model([encoder_input, decoder_input], decoder_output)\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9fhqwCvk8Sl",
        "outputId": "e8f791ac-76a3-41e0-e853-355b4ce9a25d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_9 (InputLayer)           [(None, 30)]         0           []                               \n",
            "                                                                                                  \n",
            " embedding_4 (Embedding)        (None, 30, 200)      6162400     ['input_9[0][0]']                \n",
            "                                                                                                  \n",
            " bidirectional_8 (Bidirectional  [(None, 30, 400),   641600      ['embedding_4[2][0]']            \n",
            " )                               (None, 200),                                                     \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200),                                                     \n",
            "                                 (None, 200)]                                                     \n",
            "                                                                                                  \n",
            " input_10 (InputLayer)          [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " bidirectional_9 (Bidirectional  [(None, 30, 400),   961600      ['bidirectional_8[0][0]',        \n",
            " )                               (None, 200),                     'bidirectional_8[0][1]',        \n",
            "                                 (None, 200),                     'bidirectional_8[0][3]',        \n",
            "                                 (None, 200),                     'bidirectional_8[0][2]',        \n",
            "                                 (None, 200)]                     'bidirectional_8[0][4]']        \n",
            "                                                                                                  \n",
            " embedding_5 (Embedding)        (None, None, 200)    1828600     ['input_10[0][0]']               \n",
            "                                                                                                  \n",
            " concatenate_8 (Concatenate)    (None, 400)          0           ['bidirectional_9[0][1]',        \n",
            "                                                                  'bidirectional_9[0][3]']        \n",
            "                                                                                                  \n",
            " concatenate_9 (Concatenate)    (None, 400)          0           ['bidirectional_9[0][2]',        \n",
            "                                                                  'bidirectional_9[0][4]']        \n",
            "                                                                                                  \n",
            " decoder (LSTM)                 [(None, None, 400),  961600      ['embedding_5[2][0]',            \n",
            "                                 (None, 400),                     'concatenate_8[0][0]',          \n",
            "                                 (None, 400)]                     'concatenate_9[0][0]']          \n",
            "                                                                                                  \n",
            " time_distributed_4 (TimeDistri  (None, None, 9143)  3666343     ['decoder[0][0]']                \n",
            " buted)                                                                                           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 14,222,143\n",
            "Trainable params: 14,222,143\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')"
      ],
      "metadata": {
        "id": "jN95JFDkmOmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\n"
      ],
      "metadata": {
        "id": "NCe531FrmSNT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=50,callbacks=[es],batch_size=128, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))\n",
        "model.save(\"my_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hftCmo8ma8t",
        "outputId": "2c502396-cad6-46d8-f307-5d3b3edff556"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "335/335 [==============================] - 1079s 3s/step - loss: 2.6123 - val_loss: 2.2235\n",
            "Epoch 2/50\n",
            "335/335 [==============================] - 1069s 3s/step - loss: 2.3214 - val_loss: 2.1317\n",
            "Epoch 3/50\n",
            "335/335 [==============================] - 1084s 3s/step - loss: 2.2176 - val_loss: 2.0606\n",
            "Epoch 4/50\n",
            "335/335 [==============================] - 1091s 3s/step - loss: 2.1435 - val_loss: 2.0133\n",
            "Epoch 5/50\n",
            "335/335 [==============================] - 1104s 3s/step - loss: 2.0819 - val_loss: 1.9872\n",
            "Epoch 6/50\n",
            "335/335 [==============================] - 1108s 3s/step - loss: 2.0255 - val_loss: 1.9754\n",
            "Epoch 7/50\n",
            "335/335 [==============================] - 1101s 3s/step - loss: 1.9776 - val_loss: 1.9625\n",
            "Epoch 8/50\n",
            "335/335 [==============================] - 1101s 3s/step - loss: 1.9342 - val_loss: 1.9607\n",
            "Epoch 9/50\n",
            "335/335 [==============================] - 1106s 3s/step - loss: 1.8922 - val_loss: 1.9558\n",
            "Epoch 10/50\n",
            "335/335 [==============================] - 1111s 3s/step - loss: 1.8516 - val_loss: 1.9606\n",
            "Epoch 11/50\n",
            "335/335 [==============================] - 1110s 3s/step - loss: 1.8154 - val_loss: 1.9569\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_nBPvEkKiBRT",
        "outputId": "1b71e5c4-c9aa-4144-da83-d3bceeeb414c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_target_word_index= summary_tokenizer.index_word\n",
        "reverse_source_word_index= article_tokenizer.index_word\n",
        "target_word_index=summary_tokenizer.word_index\n",
        "\n",
        "# Encode the input sequence to get the feature vector\n",
        "encoder_model = keras.Model(inputs=encoder_input,outputs=[encoder1_output, state_h2, state_c2])\n",
        "\n",
        "# Decoder setup\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_input =  Input(shape=( None,))\n",
        "decoder_state_input_h = Input(shape=(400,))\n",
        "decoder_state_input_c = Input(shape=(400,))\n",
        "decoder_hidden_state_input = Input(shape=(max_text_len,400))\n",
        "decode_input_states = [decoder_state_input_h, decoder_state_input_c]\n",
        "# Get the embeddings of the decoder sequence\n",
        "decoder_embedded1 = decoder_embedding_layer(decoder_input)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h3, state_c3 = decoder_LSTM(decoder_embedded1, initial_state=decode_input_states)\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2) \n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_input] + [decoder_hidden_state_input, decoder_state_input_h,decoder_state_input_c],\n",
        "    [decoder_outputs2] + [state_h3, state_c3])\n",
        "\n",
        "\n",
        "def conversion_to_wordsummary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if((i!=0 and i!=target_word_index['sostok']) and i!=target_word_index['eostok']):\n",
        "            newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def conversion_to_articletext(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "        if(i!=0):\n",
        "            newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    target_seq = np.zeros((1,1))\n",
        "    target_seq[0, 0] = target_word_index['sostok']\n",
        "    decoded_sentence = ''\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "    stop_condition = False\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out,e_h, e_c])\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "        \n",
        "        if(sampled_token!='eostok'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'eostok'  or len(decoded_sentence.split()) >= (max_summary_len-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence\n",
        "\n",
        "for i in range(0,10):\n",
        "    print(\"Review:\",conversion_to_articletext(x_tr[i]))\n",
        "    print(\"Original summary:\",conversion_to_wordsummary(y_tr[i]))\n",
        "    print(\"Predicted summary:\",decode_sequence(x_tr[i].reshape(1,max_text_len)))\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-P-5KKciJM2",
        "outputId": "360cc54d-0dc6-4c1a-fc01-be16bf20624e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: exceptionally wonderful transaction mixup item contact seller issue resolved simply easily ill tell mixup really get know professional seller one top notch \n",
            "Original summary: fantastic \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: cooky better lemon one still tasty one \n",
            "Original summary: glutinfree cooky \n",
            "Predicted summary:  good\n",
            "\n",
            "\n",
            "Review: searched everywhere coffee could roast certified organic fair trade coffee much better stuff grocery store even fancy coffee place additionally price good shipping fast \n",
            "Original summary: fair trade organic super tasty \n",
            "Predicted summary:  good coffee\n",
            "\n",
            "\n",
            "Review: used buy drink froma local store unfortunatly store getting time drink sweet lot pulp far delicious orange drink ever came across site buy two case \n",
            "Original summary: delicious \n",
            "Predicted summary:  best drink ever\n",
            "\n",
            "\n",
            "Review: like popcorn like hot thing stuff right heat pretty addicting always eat whole bag one sitting like burning tongue runny nose cayenne pepper like fume air get stuff \n",
            "Original summary: nice heat \n",
            "Predicted summary:  good stuff\n",
            "\n",
            "\n",
            "Review: feeding psd food year far going best food market working dog keep lean muscular year old belgian malinois \n",
            "Original summary: great food working dog \n",
            "Predicted summary:  best dog food\n",
            "\n",
            "\n",
            "Review: stuff taste kind like starbucks sugar really enjoy buy running low sugar like green tea \n",
            "Original summary: sweetness \n",
            "Predicted summary:  taste like real thing\n",
            "\n",
            "\n",
            "Review: shipping prompt product fully expected helped successful mama agatas lemon cake u flour failed \n",
            "Original summary: wonderful product \n",
            "Predicted summary:  great product\n",
            "\n",
            "\n",
            "Review: soft chewy enjoyed every bite would recommend people love cooky buy hit store \n",
            "Original summary: great \n",
            "Predicted summary:  yummy\n",
            "\n",
            "\n",
            "Review: new greenies terrific dog love worry getting sick new formulation make softer completely digestible \n",
            "Original summary: greenies grreat \n",
            "Predicted summary:  greenies\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}